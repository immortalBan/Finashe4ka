{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ktSXdQVb9Li"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L7Inb1JbiDy"
      },
      "source": [
        "## 3.1 Автоматическое дифференцирование в `torch`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsZ69HZ0EsI7"
      },
      "source": [
        "3.1.1 Воспользовавшись классами `Neuron` и `SquaredLoss` из задачи 2.4.1 и автоматическим дифференцированием, которое предоставляет `torch`, решить задачу регрессии. Для оптимизации использовать стохастический градиетный спуск."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zynPAaOrRKTm"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y, coef = make_regression(n_features=4, n_informative=4, coef=True, bias=0.5)\n",
        "X = torch.from_numpy(X).to(dtype=torch.float32)\n",
        "y = torch.from_numpy(y).to(dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POB7FdK5JHPw"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "    def __init__(self, n_inputs):\n",
        "        # <создать атрибуты объекта weights и bias>\n",
        "        # Создаем случайные веса и смещение нужных размерностей\n",
        "        self.W = torch.randn(n_inputs)\n",
        "        self.B = torch.randn(1)    \n",
        "  \n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        return torch.matmul(inputs, self.W.T) + self.B\n",
        "      \n",
        "    def backward(self, dvalue):\n",
        "         \n",
        "        self.dweights = dvalue * self.inputs\n",
        "        self.dinput =  dvalue * self.W\n",
        "        self.dbias = dvalue \n",
        "        \n",
        "        # Возвращаем градиент весов и смещения\n",
        "        return self.dweights, self.dbias\n",
        "\n",
        "class SquaredLoss:\n",
        "  def forward(self, y_pred, y_true):\n",
        "    self.y_pred = torch.tensor(y_pred, requires_grad=True)\n",
        "    y_true = torch.tensor(y_true)\n",
        "    z = (self.y_pred - y_true) ** 2\n",
        "    self.z = z\n",
        "    return z\n",
        "\n",
        "  def backward(self):\n",
        "    self.z.backward()\n",
        "    self.dinput = self.y_pred.grad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNvhB639JHPy",
        "outputId": "aef6fdfe-d65f-4e1a-d7fd-75fb98e4c5c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2981.)\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: tensor([11974.2051], grad_fn=<PowBackward0>)\n",
            "Epoch 1 loss: tensor([2608.8486], grad_fn=<PowBackward0>)\n",
            "Epoch 2 loss: tensor([4992.9136], grad_fn=<PowBackward0>)\n",
            "Epoch 3 loss: tensor([7.9374], grad_fn=<PowBackward0>)\n",
            "Epoch 4 loss: tensor([662.3904], grad_fn=<PowBackward0>)\n",
            "Epoch 5 loss: tensor([640.8123], grad_fn=<PowBackward0>)\n",
            "Epoch 6 loss: tensor([170.5280], grad_fn=<PowBackward0>)\n",
            "Epoch 7 loss: tensor([0.6339], grad_fn=<PowBackward0>)\n",
            "Epoch 8 loss: tensor([218.5606], grad_fn=<PowBackward0>)\n",
            "Epoch 9 loss: tensor([39.9030], grad_fn=<PowBackward0>)\n",
            "Epoch 10 loss: tensor([64.1313], grad_fn=<PowBackward0>)\n",
            "Epoch 11 loss: tensor([1.9663], grad_fn=<PowBackward0>)\n",
            "Epoch 12 loss: tensor([23.0864], grad_fn=<PowBackward0>)\n",
            "Epoch 13 loss: tensor([0.4170], grad_fn=<PowBackward0>)\n",
            "Epoch 14 loss: tensor([0.4293], grad_fn=<PowBackward0>)\n",
            "Epoch 15 loss: tensor([6.1182], grad_fn=<PowBackward0>)\n",
            "Epoch 16 loss: tensor([0.2745], grad_fn=<PowBackward0>)\n",
            "Epoch 17 loss: tensor([0.0016], grad_fn=<PowBackward0>)\n",
            "Epoch 18 loss: tensor([0.2150], grad_fn=<PowBackward0>)\n",
            "Epoch 19 loss: tensor([0.0287], grad_fn=<PowBackward0>)\n",
            "Epoch 20 loss: tensor([0.1527], grad_fn=<PowBackward0>)\n",
            "Epoch 21 loss: tensor([0.1105], grad_fn=<PowBackward0>)\n",
            "Epoch 22 loss: tensor([0.4526], grad_fn=<PowBackward0>)\n",
            "Epoch 23 loss: tensor([0.0616], grad_fn=<PowBackward0>)\n",
            "Epoch 24 loss: tensor([0.4451], grad_fn=<PowBackward0>)\n",
            "Epoch 25 loss: tensor([0.0655], grad_fn=<PowBackward0>)\n",
            "Epoch 26 loss: tensor([0.0193], grad_fn=<PowBackward0>)\n",
            "Epoch 27 loss: tensor([0.0061], grad_fn=<PowBackward0>)\n",
            "Epoch 28 loss: tensor([0.0069], grad_fn=<PowBackward0>)\n",
            "Epoch 29 loss: tensor([0.0002], grad_fn=<PowBackward0>)\n",
            "Epoch 30 loss: tensor([0.0141], grad_fn=<PowBackward0>)\n",
            "Epoch 31 loss: tensor([0.0065], grad_fn=<PowBackward0>)\n",
            "Epoch 32 loss: tensor([0.0034], grad_fn=<PowBackward0>)\n",
            "Epoch 33 loss: tensor([0.0013], grad_fn=<PowBackward0>)\n",
            "Epoch 34 loss: tensor([0.0018], grad_fn=<PowBackward0>)\n",
            "Epoch 35 loss: tensor([0.0003], grad_fn=<PowBackward0>)\n",
            "Epoch 36 loss: tensor([7.6846e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 37 loss: tensor([0.0008], grad_fn=<PowBackward0>)\n",
            "Epoch 38 loss: tensor([9.8371e-09], grad_fn=<PowBackward0>)\n",
            "Epoch 39 loss: tensor([0.0001], grad_fn=<PowBackward0>)\n",
            "Epoch 40 loss: tensor([0.0003], grad_fn=<PowBackward0>)\n",
            "Epoch 41 loss: tensor([0.0002], grad_fn=<PowBackward0>)\n",
            "Epoch 42 loss: tensor([7.1718e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 43 loss: tensor([5.1344e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 44 loss: tensor([2.0573e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 45 loss: tensor([2.0650e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 46 loss: tensor([2.8772e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 47 loss: tensor([1.5166e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 48 loss: tensor([3.4089e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 49 loss: tensor([1.3626e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 50 loss: tensor([1.8443e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 51 loss: tensor([4.7148e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 52 loss: tensor([2.2016e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 53 loss: tensor([3.0109e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 54 loss: tensor([1.0296e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 55 loss: tensor([1.1269e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 56 loss: tensor([6.2957e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 57 loss: tensor([7.5437e-08], grad_fn=<PowBackward0>)\n",
            "Epoch 58 loss: tensor([4.5635e-08], grad_fn=<PowBackward0>)\n",
            "Epoch 59 loss: tensor([1.1409e-08], grad_fn=<PowBackward0>)\n",
            "Epoch 60 loss: tensor([5.4148e-08], grad_fn=<PowBackward0>)\n",
            "Epoch 61 loss: tensor([1.4334e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 62 loss: tensor([4.2433e-08], grad_fn=<PowBackward0>)\n",
            "Epoch 63 loss: tensor([2.8522e-09], grad_fn=<PowBackward0>)\n",
            "Epoch 64 loss: tensor([4.1439e-09], grad_fn=<PowBackward0>)\n",
            "Epoch 65 loss: tensor([1.1409e-08], grad_fn=<PowBackward0>)\n",
            "Epoch 66 loss: tensor([1.3097e-08], grad_fn=<PowBackward0>)\n",
            "Epoch 67 loss: tensor([9.3132e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 68 loss: tensor([4.7148e-09], grad_fn=<PowBackward0>)\n",
            "Epoch 69 loss: tensor([5.2387e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 70 loss: tensor([2.0955e-09], grad_fn=<PowBackward0>)\n",
            "Epoch 71 loss: tensor([2.3283e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 72 loss: tensor([1.1787e-09], grad_fn=<PowBackward0>)\n",
            "Epoch 73 loss: tensor([9.3132e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 74 loss: tensor([0.], grad_fn=<PowBackward0>)\n",
            "Epoch 75 loss: tensor([2.3283e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 76 loss: tensor([5.8208e-11], grad_fn=<PowBackward0>)\n",
            "Epoch 77 loss: tensor([5.2387e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 78 loss: tensor([4.4565e-11], grad_fn=<PowBackward0>)\n",
            "Epoch 79 loss: tensor([1.4552e-11], grad_fn=<PowBackward0>)\n",
            "Epoch 80 loss: tensor([2.3283e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 81 loss: tensor([2.3283e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 82 loss: tensor([1.4552e-09], grad_fn=<PowBackward0>)\n",
            "Epoch 83 loss: tensor([7.3669e-11], grad_fn=<PowBackward0>)\n",
            "Epoch 84 loss: tensor([4.4020e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 85 loss: tensor([0.], grad_fn=<PowBackward0>)\n",
            "Epoch 86 loss: tensor([0.], grad_fn=<PowBackward0>)\n",
            "Epoch 87 loss: tensor([7.1304e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 88 loss: tensor([2.9468e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 89 loss: tensor([7.1304e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 90 loss: tensor([7.1304e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 91 loss: tensor([0.], grad_fn=<PowBackward0>)\n",
            "Epoch 92 loss: tensor([1.8417e-09], grad_fn=<PowBackward0>)\n",
            "Epoch 93 loss: tensor([2.3283e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 94 loss: tensor([2.3283e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 95 loss: tensor([9.3132e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 96 loss: tensor([5.2387e-10], grad_fn=<PowBackward0>)\n",
            "Epoch 97 loss: tensor([5.8208e-11], grad_fn=<PowBackward0>)\n",
            "Epoch 98 loss: tensor([5.8208e-11], grad_fn=<PowBackward0>)\n",
            "Epoch 99 loss: tensor([2.3283e-10], grad_fn=<PowBackward0>)\n"
          ]
        }
      ],
      "source": [
        "n_inputs = 4# <размерность элемента выборки >\n",
        "learning_rate = 0.01 #  скорость обучения\n",
        "n_epoch = 100 #  количество эпох\n",
        "batch_size = 10\n",
        "\n",
        "neuron = Neuron(n_inputs)\n",
        "loss = SquaredLoss()\n",
        "\n",
        "losses = []\n",
        "for epoch in range(100):\n",
        "  sample = torch.randint(0, X.shape[0], size=(batch_size,))\n",
        "  for x_example, y_example in zip(X[sample], y[sample]):\n",
        "    # forward pass\n",
        "    y_pred = neuron.forward(x_example)\n",
        "    curr_loss = loss.forward(y_pred, y_example)\n",
        "    losses.append(curr_loss)\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    dweights, dbias = neuron.backward(loss.dinput)\n",
        "\n",
        "    # update weights\n",
        "    neuron.W -= learning_rate * dweights\n",
        "    neuron.B -= learning_rate * dbias\n",
        "  print(f\"Epoch {epoch} loss: {curr_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxWeyJw5lAqU"
      },
      "source": [
        "3.1.2 Воспользовавшись классами `Linear` и `MSELoss` из задачи 2.1.4 и 2.3.1, `ReLU` из 2.2.1 и автоматическим дифференцированием, которое предоставляет `torch`, решить задачу регрессии. Для оптимизации использовать пакетный градиентный спуск. Вывести график функции потерь в зависимости от номера эпохи. Вывести на одном графике исходные данные и предсказанные значения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnlAt1NEQoat"
      },
      "outputs": [],
      "source": [
        "X = torch.FloatTensor(torch.linspace(0, 1, 100).view(-1, 1))\n",
        "y = torch.sin(2 * np.pi * X) + 0.1 * torch.rand(X.size()) \n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, inputs):\n",
        "        inputs[inputs < 0] = 0\n",
        "        return inputs\n",
        "    \n",
        "class MSELoss:\n",
        "  def forward(self, y_pred, y_true):\n",
        "    self.y_pred = torch.tensor(y_pred, requires_grad=True)\n",
        "    y_true = torch.tensor(y_true)\n",
        "    z = ((self.y_pred - y_true) ** 2).mean()\n",
        "    self.z = z\n",
        "    return z\n",
        "\n",
        "  def backward(self):\n",
        "    self.z.backward()\n",
        "    self.dinput = self.y_pred.grad\n",
        "\n",
        "class Linear:\n",
        "    def __init__(self, n_features, n_neurons):\n",
        "        self.weights = torch.randn(n_features, n_neurons)\n",
        "        self.biases = torch.randn(n_neurons)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        return torch.matmul(inputs, self.weights) + self.biases\n",
        "    \n",
        "    def backward(self, dvalues):\n",
        "        self.dweights = torch.matmul(self.inputs.T, dvalues)\n",
        "        self.dbiases = torch.sum(dvalues, axis=0)\n",
        "        self.dinputs = torch.matmul(dvalues, self.weights.T)\n",
        "        return self.dweights, self.dbiases\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24ZeSDTxJHP0",
        "outputId": "47050713-907c-4d79-e3f1-6bc5867ba171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: 2.3058769702911377\n",
            "Epoch 1 loss: 2.2186713218688965\n",
            "Epoch 2 loss: 2.135784387588501\n",
            "Epoch 3 loss: 2.056999921798706\n",
            "Epoch 4 loss: 1.9821122884750366\n",
            "Epoch 5 loss: 1.9109264612197876\n",
            "Epoch 6 loss: 1.843258023262024\n",
            "Epoch 7 loss: 1.7789300680160522\n",
            "Epoch 8 loss: 1.7177757024765015\n",
            "Epoch 9 loss: 1.6596364974975586\n",
            "Epoch 10 loss: 1.604360818862915\n",
            "Epoch 11 loss: 1.5518062114715576\n",
            "Epoch 12 loss: 1.5018359422683716\n",
            "Epoch 13 loss: 1.454321265220642\n",
            "Epoch 14 loss: 1.409138798713684\n",
            "Epoch 15 loss: 1.3661723136901855\n",
            "Epoch 16 loss: 1.3253109455108643\n",
            "Epoch 17 loss: 1.2864493131637573\n",
            "Epoch 18 loss: 1.2494869232177734\n",
            "Epoch 19 loss: 1.214329481124878\n",
            "Epoch 20 loss: 1.1808863878250122\n",
            "Epoch 21 loss: 1.1490720510482788\n",
            "Epoch 22 loss: 1.1188048124313354\n",
            "Epoch 23 loss: 1.0900077819824219\n",
            "Epoch 24 loss: 1.0626070499420166\n",
            "Epoch 25 loss: 1.0365328788757324\n",
            "Epoch 26 loss: 1.0117191076278687\n",
            "Epoch 27 loss: 0.9881026744842529\n",
            "Epoch 28 loss: 0.9656236171722412\n",
            "Epoch 29 loss: 0.9442253112792969\n",
            "Epoch 30 loss: 0.9238536357879639\n",
            "Epoch 31 loss: 0.9044572710990906\n",
            "Epoch 32 loss: 0.8859875202178955\n",
            "Epoch 33 loss: 0.8683981895446777\n",
            "Epoch 34 loss: 0.8516452312469482\n",
            "Epoch 35 loss: 0.8356870412826538\n",
            "Epoch 36 loss: 0.8204836249351501\n",
            "Epoch 37 loss: 0.8059974908828735\n",
            "Epoch 38 loss: 0.7921929359436035\n",
            "Epoch 39 loss: 0.7790358066558838\n",
            "Epoch 40 loss: 0.7664938569068909\n",
            "Epoch 41 loss: 0.7545362710952759\n",
            "Epoch 42 loss: 0.743134081363678\n",
            "Epoch 43 loss: 0.7322595715522766\n",
            "Epoch 44 loss: 0.7218862771987915\n",
            "Epoch 45 loss: 0.7119894623756409\n",
            "Epoch 46 loss: 0.7025451064109802\n",
            "Epoch 47 loss: 0.6935308575630188\n",
            "Epoch 48 loss: 0.6849252581596375\n",
            "Epoch 49 loss: 0.676707923412323\n",
            "Epoch 50 loss: 0.6688595414161682\n",
            "Epoch 51 loss: 0.6613617539405823\n",
            "Epoch 52 loss: 0.6541971564292908\n",
            "Epoch 53 loss: 0.6473489999771118\n",
            "Epoch 54 loss: 0.6408018469810486\n",
            "Epoch 55 loss: 0.6345404982566833\n",
            "Epoch 56 loss: 0.6285508871078491\n",
            "Epoch 57 loss: 0.6228193044662476\n",
            "Epoch 58 loss: 0.6173332929611206\n",
            "Epoch 59 loss: 0.6120803952217102\n",
            "Epoch 60 loss: 0.6070491671562195\n",
            "Epoch 61 loss: 0.6022285223007202\n",
            "Epoch 62 loss: 0.597608208656311\n",
            "Epoch 63 loss: 0.5931780338287354\n",
            "Epoch 64 loss: 0.5889288187026978\n",
            "Epoch 65 loss: 0.5848515033721924\n",
            "Epoch 66 loss: 0.5809376239776611\n",
            "Epoch 67 loss: 0.5771791338920593\n",
            "Epoch 68 loss: 0.5735682845115662\n",
            "Epoch 69 loss: 0.570097804069519\n",
            "Epoch 70 loss: 0.5667608380317688\n",
            "Epoch 71 loss: 0.5635507106781006\n",
            "Epoch 72 loss: 0.5604612827301025\n",
            "Epoch 73 loss: 0.5574865937232971\n",
            "Epoch 74 loss: 0.5546209216117859\n",
            "Epoch 75 loss: 0.5518590211868286\n",
            "Epoch 76 loss: 0.5491957664489746\n",
            "Epoch 77 loss: 0.5466263294219971\n",
            "Epoch 78 loss: 0.5441460609436035\n",
            "Epoch 79 loss: 0.5417506694793701\n",
            "Epoch 80 loss: 0.539435863494873\n",
            "Epoch 81 loss: 0.5371979475021362\n",
            "Epoch 82 loss: 0.5350330471992493\n",
            "Epoch 83 loss: 0.5329377055168152\n",
            "Epoch 84 loss: 0.5309083461761475\n",
            "Epoch 85 loss: 0.5289419293403625\n",
            "Epoch 86 loss: 0.5270353555679321\n",
            "Epoch 87 loss: 0.525185763835907\n",
            "Epoch 88 loss: 0.5233903527259827\n",
            "Epoch 89 loss: 0.5216465592384338\n",
            "Epoch 90 loss: 0.5199518203735352\n",
            "Epoch 91 loss: 0.5183039307594299\n",
            "Epoch 92 loss: 0.5167005062103271\n",
            "Epoch 93 loss: 0.5151394605636597\n",
            "Epoch 94 loss: 0.5136188268661499\n",
            "Epoch 95 loss: 0.5121366381645203\n",
            "Epoch 96 loss: 0.5106910467147827\n",
            "Epoch 97 loss: 0.5092804431915283\n",
            "Epoch 98 loss: 0.507902979850769\n",
            "Epoch 99 loss: 0.5065572261810303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "n_inputs = 1# <размерность элемента выборки >\n",
        "learning_rate = 0.01 #  скорость обучения\n",
        "n_epoch = 100 #  количество эпох\n",
        "\n",
        "neuron = Linear(1, 1)\n",
        "loss = MSELoss()\n",
        "activation = ReLU()\n",
        "\n",
        "losses = []\n",
        "for epoch in range(n_epoch):\n",
        "    y_pred = activation.forward(neuron.forward(X))\n",
        "\n",
        "    curr_loss = loss.forward(y_pred, y)\n",
        "    #print(loss.z)\n",
        "    losses.append(curr_loss)\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    dweights, dbias = neuron.backward(loss.dinput)\n",
        "    #print(loss.dinput)\n",
        "\n",
        "    # update weights\n",
        "    neuron.weights -= learning_rate * dweights\n",
        "    neuron.biases -= learning_rate * dbias\n",
        "    print(f\"Epoch {epoch} loss: {curr_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nifm0FVB2y5N"
      },
      "source": [
        "## 3.2 Алгоритмы оптимизации в `torch.optim`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5PTTYou3xx8"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oBFfJpmcwfn"
      },
      "source": [
        "3.2.1 Решить задачу 3.1.1, воспользовавшись оптимизатором `optim.SDG` для применения стохастического градиентого спуска"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFaBW1I2Bb8f"
      },
      "outputs": [],
      "source": [
        "X, y, coef = make_regression(n_features=4, n_informative=4, coef=True, bias=0.5)\n",
        "X = torch.from_numpy(X).to(dtype=torch.float32)\n",
        "y = torch.from_numpy(y).to(dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPYOnmIaPU_4"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "    def __init__(self, n_inputs):\n",
        "        # <создать атрибуты объекта weights и bias>\n",
        "        # Создаем случайные веса и смещение нужных размерностей\n",
        "        self.W = torch.nn.Parameter(torch.randn(1, n_inputs, requires_grad=True))\n",
        "        self.B = torch.nn.Parameter(torch.randn(1, requires_grad=True))\n",
        "      \n",
        "    def parameters(self):\n",
        "        yield self.W\n",
        "        yield self.B\n",
        "  \n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        return torch.matmul(inputs, self.W.T) + self.B\n",
        "      \n",
        "    def backward(self, dvalue):\n",
        "        with torch.no_grad():\n",
        "         \n",
        "          self.dweights = dvalue * self.inputs\n",
        "          self.dinput =  dvalue * self.W\n",
        "          self.dbias = dvalue \n",
        "        \n",
        "        # Возвращаем градиент весов и смещения\n",
        "        return self.dweights, self.dbias\n",
        "\n",
        "class SquaredLoss:\n",
        "  def forward(self, y_pred, y_true):\n",
        "    self.y_pred = y_pred\n",
        "    self.y_true = y_true\n",
        "    self.loss = (y_pred - y_true)**2\n",
        "    return self.loss\n",
        "\n",
        "  def backward(self):\n",
        "    y_pred = torch.autograd.Variable(self.y_pred, requires_grad=True)\n",
        "    y_true = torch.autograd.Variable(self.y_true, requires_grad=False)\n",
        "    ((y_pred - y_true)**2).backward()\n",
        "    self.dinput = y_pred.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPfBGzyQBjN1",
        "outputId": "b901fe16-31c6-4f35-ba38-79be7816e1a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: tensor([3755.0574], grad_fn=<PowBackward0>)\n",
            "Epoch 1 loss: tensor([2450.0933], grad_fn=<PowBackward0>)\n",
            "Epoch 2 loss: tensor([1586.8700], grad_fn=<PowBackward0>)\n",
            "Epoch 3 loss: tensor([1019.0901], grad_fn=<PowBackward0>)\n",
            "Epoch 4 loss: tensor([648.0484], grad_fn=<PowBackward0>)\n",
            "Epoch 5 loss: tensor([407.3742], grad_fn=<PowBackward0>)\n",
            "Epoch 6 loss: tensor([252.6056], grad_fn=<PowBackward0>)\n",
            "Epoch 7 loss: tensor([154.0840], grad_fn=<PowBackward0>)\n",
            "Epoch 8 loss: tensor([92.1203], grad_fn=<PowBackward0>)\n",
            "Epoch 9 loss: tensor([53.7130], grad_fn=<PowBackward0>)\n",
            "Epoch 10 loss: tensor([30.3312], grad_fn=<PowBackward0>)\n",
            "Epoch 11 loss: tensor([16.4172], grad_fn=<PowBackward0>)\n",
            "Epoch 12 loss: tensor([8.3811], grad_fn=<PowBackward0>)\n",
            "Epoch 13 loss: tensor([3.9262], grad_fn=<PowBackward0>)\n",
            "Epoch 14 loss: tensor([1.6014], grad_fn=<PowBackward0>)\n",
            "Epoch 15 loss: tensor([0.5034], grad_fn=<PowBackward0>)\n",
            "Epoch 16 loss: tensor([0.0799], grad_fn=<PowBackward0>)\n",
            "Epoch 17 loss: tensor([0.0016], grad_fn=<PowBackward0>)\n",
            "Epoch 18 loss: tensor([0.0784], grad_fn=<PowBackward0>)\n",
            "Epoch 19 loss: tensor([0.2057], grad_fn=<PowBackward0>)\n",
            "Epoch 20 loss: tensor([0.3301], grad_fn=<PowBackward0>)\n",
            "Epoch 21 loss: tensor([0.4284], grad_fn=<PowBackward0>)\n",
            "Epoch 22 loss: tensor([0.4931], grad_fn=<PowBackward0>)\n",
            "Epoch 23 loss: tensor([0.5258], grad_fn=<PowBackward0>)\n",
            "Epoch 24 loss: tensor([0.5317], grad_fn=<PowBackward0>)\n",
            "Epoch 25 loss: tensor([0.5171], grad_fn=<PowBackward0>)\n",
            "Epoch 26 loss: tensor([0.4882], grad_fn=<PowBackward0>)\n",
            "Epoch 27 loss: tensor([0.4501], grad_fn=<PowBackward0>)\n",
            "Epoch 28 loss: tensor([0.4072], grad_fn=<PowBackward0>)\n",
            "Epoch 29 loss: tensor([0.3627], grad_fn=<PowBackward0>)\n",
            "Epoch 30 loss: tensor([0.3189], grad_fn=<PowBackward0>)\n",
            "Epoch 31 loss: tensor([0.2773], grad_fn=<PowBackward0>)\n",
            "Epoch 32 loss: tensor([0.2388], grad_fn=<PowBackward0>)\n",
            "Epoch 33 loss: tensor([0.2041], grad_fn=<PowBackward0>)\n",
            "Epoch 34 loss: tensor([0.1732], grad_fn=<PowBackward0>)\n",
            "Epoch 35 loss: tensor([0.1460], grad_fn=<PowBackward0>)\n",
            "Epoch 36 loss: tensor([0.1224], grad_fn=<PowBackward0>)\n",
            "Epoch 37 loss: tensor([0.1021], grad_fn=<PowBackward0>)\n",
            "Epoch 38 loss: tensor([0.0848], grad_fn=<PowBackward0>)\n",
            "Epoch 39 loss: tensor([0.0702], grad_fn=<PowBackward0>)\n",
            "Epoch 40 loss: tensor([0.0579], grad_fn=<PowBackward0>)\n",
            "Epoch 41 loss: tensor([0.0476], grad_fn=<PowBackward0>)\n",
            "Epoch 42 loss: tensor([0.0390], grad_fn=<PowBackward0>)\n",
            "Epoch 43 loss: tensor([0.0318], grad_fn=<PowBackward0>)\n",
            "Epoch 44 loss: tensor([0.0260], grad_fn=<PowBackward0>)\n",
            "Epoch 45 loss: tensor([0.0211], grad_fn=<PowBackward0>)\n",
            "Epoch 46 loss: tensor([0.0172], grad_fn=<PowBackward0>)\n",
            "Epoch 47 loss: tensor([0.0139], grad_fn=<PowBackward0>)\n",
            "Epoch 48 loss: tensor([0.0112], grad_fn=<PowBackward0>)\n",
            "Epoch 49 loss: tensor([0.0091], grad_fn=<PowBackward0>)\n",
            "Epoch 50 loss: tensor([0.0073], grad_fn=<PowBackward0>)\n",
            "Epoch 51 loss: tensor([0.0059], grad_fn=<PowBackward0>)\n",
            "Epoch 52 loss: tensor([0.0048], grad_fn=<PowBackward0>)\n",
            "Epoch 53 loss: tensor([0.0038], grad_fn=<PowBackward0>)\n",
            "Epoch 54 loss: tensor([0.0031], grad_fn=<PowBackward0>)\n",
            "Epoch 55 loss: tensor([0.0025], grad_fn=<PowBackward0>)\n",
            "Epoch 56 loss: tensor([0.0020], grad_fn=<PowBackward0>)\n",
            "Epoch 57 loss: tensor([0.0016], grad_fn=<PowBackward0>)\n",
            "Epoch 58 loss: tensor([0.0013], grad_fn=<PowBackward0>)\n",
            "Epoch 59 loss: tensor([0.0010], grad_fn=<PowBackward0>)\n",
            "Epoch 60 loss: tensor([0.0008], grad_fn=<PowBackward0>)\n",
            "Epoch 61 loss: tensor([0.0006], grad_fn=<PowBackward0>)\n",
            "Epoch 62 loss: tensor([0.0005], grad_fn=<PowBackward0>)\n",
            "Epoch 63 loss: tensor([0.0004], grad_fn=<PowBackward0>)\n",
            "Epoch 64 loss: tensor([0.0003], grad_fn=<PowBackward0>)\n",
            "Epoch 65 loss: tensor([0.0003], grad_fn=<PowBackward0>)\n",
            "Epoch 66 loss: tensor([0.0002], grad_fn=<PowBackward0>)\n",
            "Epoch 67 loss: tensor([0.0002], grad_fn=<PowBackward0>)\n",
            "Epoch 68 loss: tensor([0.0001], grad_fn=<PowBackward0>)\n",
            "Epoch 69 loss: tensor([0.0001], grad_fn=<PowBackward0>)\n",
            "Epoch 70 loss: tensor([8.2013e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 71 loss: tensor([6.5156e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 72 loss: tensor([5.1761e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 73 loss: tensor([4.1267e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 74 loss: tensor([3.3004e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 75 loss: tensor([2.6129e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 76 loss: tensor([2.0676e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 77 loss: tensor([1.6227e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 78 loss: tensor([1.2640e-05], grad_fn=<PowBackward0>)\n",
            "Epoch 79 loss: tensor([9.8804e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 80 loss: tensor([7.9686e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 81 loss: tensor([6.3773e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 82 loss: tensor([5.0312e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 83 loss: tensor([4.0876e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 84 loss: tensor([3.2419e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 85 loss: tensor([2.5670e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 86 loss: tensor([2.0138e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 87 loss: tensor([1.6625e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 88 loss: tensor([1.3448e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 89 loss: tensor([1.1085e-06], grad_fn=<PowBackward0>)\n",
            "Epoch 90 loss: tensor([8.6636e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 91 loss: tensor([7.1718e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 92 loss: tensor([5.8208e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 93 loss: tensor([4.8202e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 94 loss: tensor([3.8190e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 95 loss: tensor([3.1875e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 96 loss: tensor([2.6915e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 97 loss: tensor([2.2375e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 98 loss: tensor([1.9581e-07], grad_fn=<PowBackward0>)\n",
            "Epoch 99 loss: tensor([1.7608e-07], grad_fn=<PowBackward0>)\n"
          ]
        }
      ],
      "source": [
        "n_inputs = 4# <размерность элемента выборки >\n",
        "learning_rate = 0.001 #  скорость обучения\n",
        "n_epoch = 100 #  количество эпох\n",
        "batch_size = 10\n",
        "\n",
        "neuron = Neuron(n_inputs)\n",
        "optimizer = optim.SGD(neuron.parameters(), lr=learning_rate)\n",
        "# print(optimizer.param_groups)\n",
        "loss = SquaredLoss()\n",
        "\n",
        "losses = []\n",
        "for epoch in range(100):\n",
        "  for x_example, y_example in zip(X, y):\n",
        "      optimizer.zero_grad()\n",
        "      # forward pass\n",
        "      y_pred = neuron.forward(x_example)\n",
        "      curr_loss = loss.forward(y_pred, y_example)\n",
        "      losses.append(curr_loss)\n",
        "\n",
        "      # backward pass\n",
        "      optimizer = torch.optim.SGD(neuron.parameters(), learning_rate)\n",
        "      optimizer.zero_grad()\n",
        "      loss.forward(y_pred, y_example).backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "  print(f\"Epoch {epoch} loss: {curr_loss}\")\n",
        "  # print(optimizer.param_groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LFAacdy46bX"
      },
      "source": [
        "3.2.2 Решить задачу 3.1.2, воспользовавшись оптимизатором `optim.Adam` для применения пакетного градиентого спуска. Вывести график функции потерь в зависимости от номера эпохи. Вывести на одном графике исходные данные и предсказанные значения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFqvks3QaWXc"
      },
      "outputs": [],
      "source": [
        "X = torch.FloatTensor(torch.linspace(0, 1, 100).view(-1, 1))\n",
        "y = torch.sin(2 * np.pi * X) + 0.1 * torch.rand(X.size()) \n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, inputs):\n",
        "        inputs[inputs < 0] = 0\n",
        "        return inputs\n",
        "    \n",
        "class MSELoss:\n",
        "  def forward(self, y_pred, y_true):\n",
        "    self.loss = ((y_pred - y_true)**2).mean()\n",
        "    return self.loss\n",
        "\n",
        "  def backward(self, y_pred, y_true):\n",
        "    y_pred = torch.autograd.Variable(y_pred, requires_grad=True)\n",
        "    y_true = torch.autograd.Variable(y_true, requires_grad=False)\n",
        "    (((y_pred - y_true)**2).mean()).backward()\n",
        "    self.dinput = y_pred.grad\n",
        "\n",
        "class Linear:\n",
        "    def __init__(self, n_features, n_neurons):\n",
        "        self.weights = torch.nn.Parameter(torch.randn(n_features, n_neurons), requires_grad=True) \n",
        "        self.biases = torch.nn.Parameter(torch.randn(n_neurons), requires_grad=True)\n",
        "      \n",
        "    def parameters(self):\n",
        "        yield self.weights\n",
        "        yield self.biases\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        return torch.matmul(inputs, self.weights) + self.biases\n",
        "    \n",
        "    def backward(self, dvalues):\n",
        "        self.dweights = torch.matmul(self.inputs.T, dvalues)\n",
        "        self.dbiases = torch.sum(dvalues, axis=0)\n",
        "        self.dinputs = torch.matmul(dvalues, self.weights.T)\n",
        "        return self.dweights, self.dbiases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMFidb6hb9jf",
        "outputId": "e8212be1-0a2f-4344-f512-25a4c420f118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: 3.853825092315674\n",
            "Epoch 1 loss: 2.687979221343994\n",
            "Epoch 2 loss: 2.047274351119995\n",
            "Epoch 3 loss: 1.435421109199524\n",
            "Epoch 4 loss: 0.9206600785255432\n",
            "Epoch 5 loss: 0.623136579990387\n",
            "Epoch 6 loss: 0.4487867057323456\n",
            "Epoch 7 loss: 0.30159956216812134\n",
            "Epoch 8 loss: 0.22068829834461212\n",
            "Epoch 9 loss: 0.24662992358207703\n",
            "Epoch 10 loss: 0.31665369868278503\n",
            "Epoch 11 loss: 0.3635810613632202\n",
            "Epoch 12 loss: 0.405632883310318\n",
            "Epoch 13 loss: 0.46548396348953247\n",
            "Epoch 14 loss: 0.5106430649757385\n",
            "Epoch 15 loss: 0.5102164149284363\n",
            "Epoch 16 loss: 0.48280999064445496\n",
            "Epoch 17 loss: 0.4548150897026062\n",
            "Epoch 18 loss: 0.41997599601745605\n",
            "Epoch 19 loss: 0.36499008536338806\n",
            "Epoch 20 loss: 0.30253639817237854\n",
            "Epoch 21 loss: 0.2535729706287384\n",
            "Epoch 22 loss: 0.21824230253696442\n",
            "Epoch 23 loss: 0.18506751954555511\n",
            "Epoch 24 loss: 0.15666666626930237\n",
            "Epoch 25 loss: 0.14437809586524963\n",
            "Epoch 26 loss: 0.14595775306224823\n",
            "Epoch 27 loss: 0.1492205262184143\n",
            "Epoch 28 loss: 0.15192651748657227\n",
            "Epoch 29 loss: 0.159931942820549\n",
            "Epoch 30 loss: 0.17078781127929688\n",
            "Epoch 31 loss: 0.1756683737039566\n",
            "Epoch 32 loss: 0.17406083643436432\n",
            "Epoch 33 loss: 0.17152398824691772\n",
            "Epoch 34 loss: 0.16745102405548096\n",
            "Epoch 35 loss: 0.1578129529953003\n",
            "Epoch 36 loss: 0.1449623852968216\n",
            "Epoch 37 loss: 0.13404612243175507\n",
            "Epoch 38 loss: 0.12464217096567154\n",
            "Epoch 39 loss: 0.11449912935495377\n",
            "Epoch 40 loss: 0.10617878288030624\n",
            "Epoch 41 loss: 0.10206901282072067\n",
            "Epoch 42 loss: 0.09994851797819138\n",
            "Epoch 43 loss: 0.09798001497983932\n",
            "Epoch 44 loss: 0.09768802672624588\n",
            "Epoch 45 loss: 0.0990406796336174\n",
            "Epoch 46 loss: 0.09950225800275803\n",
            "Epoch 47 loss: 0.09861242026090622\n",
            "Epoch 48 loss: 0.09771591424942017\n",
            "Epoch 49 loss: 0.0961819663643837\n",
            "Epoch 50 loss: 0.09299414604902267\n",
            "Epoch 51 loss: 0.08927703648805618\n",
            "Epoch 52 loss: 0.08597046136856079\n",
            "Epoch 53 loss: 0.0824289545416832\n",
            "Epoch 54 loss: 0.07879974693059921\n",
            "Epoch 55 loss: 0.07613794505596161\n",
            "Epoch 56 loss: 0.07423416525125504\n",
            "Epoch 57 loss: 0.07246016710996628\n",
            "Epoch 58 loss: 0.07122599333524704\n",
            "Epoch 59 loss: 0.07061000168323517\n",
            "Epoch 60 loss: 0.06986896693706512\n",
            "Epoch 61 loss: 0.06893069297075272\n",
            "Epoch 62 loss: 0.0680956095457077\n",
            "Epoch 63 loss: 0.0669863149523735\n",
            "Epoch 64 loss: 0.06544238328933716\n",
            "Epoch 65 loss: 0.06389401853084564\n",
            "Epoch 66 loss: 0.06235615164041519\n",
            "Epoch 67 loss: 0.060673218220472336\n",
            "Epoch 68 loss: 0.059139471501111984\n",
            "Epoch 69 loss: 0.057882100343704224\n",
            "Epoch 70 loss: 0.05669253692030907\n",
            "Epoch 71 loss: 0.055666401982307434\n",
            "Epoch 72 loss: 0.054883189499378204\n",
            "Epoch 73 loss: 0.054151665419340134\n",
            "Epoch 74 loss: 0.05340093746781349\n",
            "Epoch 75 loss: 0.052716419100761414\n",
            "Epoch 76 loss: 0.0519651398062706\n",
            "Epoch 77 loss: 0.05111498758196831\n",
            "Epoch 78 loss: 0.05027981102466583\n",
            "Epoch 79 loss: 0.04942288249731064\n",
            "Epoch 80 loss: 0.04852728545665741\n",
            "Epoch 81 loss: 0.04769621789455414\n",
            "Epoch 82 loss: 0.04692363739013672\n",
            "Epoch 83 loss: 0.04617016017436981\n",
            "Epoch 84 loss: 0.04549536854028702\n",
            "Epoch 85 loss: 0.04487958550453186\n",
            "Epoch 86 loss: 0.04426753520965576\n",
            "Epoch 87 loss: 0.04368637129664421\n",
            "Epoch 88 loss: 0.043126340955495834\n",
            "Epoch 89 loss: 0.042537566274404526\n",
            "Epoch 90 loss: 0.04194645956158638\n",
            "Epoch 91 loss: 0.04135334864258766\n",
            "Epoch 92 loss: 0.04073987156152725\n",
            "Epoch 93 loss: 0.0401410236954689\n",
            "Epoch 94 loss: 0.03956076130270958\n",
            "Epoch 95 loss: 0.038988254964351654\n",
            "Epoch 96 loss: 0.03844407573342323\n",
            "Epoch 97 loss: 0.03792709857225418\n",
            "Epoch 98 loss: 0.037420693784952164\n",
            "Epoch 99 loss: 0.036925945430994034\n",
            "Epoch 100 loss: 0.036436423659324646\n",
            "Epoch 101 loss: 0.0359453409910202\n",
            "Epoch 102 loss: 0.035461802035570145\n",
            "Epoch 103 loss: 0.03498140722513199\n",
            "Epoch 104 loss: 0.034501709043979645\n",
            "Epoch 105 loss: 0.034033890813589096\n",
            "Epoch 106 loss: 0.033573176711797714\n",
            "Epoch 107 loss: 0.033118270337581635\n",
            "Epoch 108 loss: 0.03267529606819153\n",
            "Epoch 109 loss: 0.03224192187190056\n",
            "Epoch 110 loss: 0.0318182148039341\n",
            "Epoch 111 loss: 0.031404998153448105\n",
            "Epoch 112 loss: 0.030997037887573242\n",
            "Epoch 113 loss: 0.03059486113488674\n",
            "Epoch 114 loss: 0.03019878640770912\n",
            "Epoch 115 loss: 0.029803719371557236\n",
            "Epoch 116 loss: 0.029406972229480743\n",
            "Epoch 117 loss: 0.029018767178058624\n",
            "Epoch 118 loss: 0.028636466711759567\n",
            "Epoch 119 loss: 0.028262196108698845\n",
            "Epoch 120 loss: 0.027895623818039894\n",
            "Epoch 121 loss: 0.027535727247595787\n",
            "Epoch 122 loss: 0.02718438394367695\n",
            "Epoch 123 loss: 0.026836872100830078\n",
            "Epoch 124 loss: 0.026492252945899963\n",
            "Epoch 125 loss: 0.026154775172472\n",
            "Epoch 126 loss: 0.02582169510424137\n",
            "Epoch 127 loss: 0.025494122877717018\n",
            "Epoch 128 loss: 0.02517174743115902\n",
            "Epoch 129 loss: 0.0248553529381752\n",
            "Epoch 130 loss: 0.024545378983020782\n",
            "Epoch 131 loss: 0.024240411818027496\n",
            "Epoch 132 loss: 0.023938840255141258\n",
            "Epoch 133 loss: 0.02364290878176689\n",
            "Epoch 134 loss: 0.023351898416876793\n",
            "Epoch 135 loss: 0.02306598238646984\n",
            "Epoch 136 loss: 0.022785291075706482\n",
            "Epoch 137 loss: 0.022509312257170677\n",
            "Epoch 138 loss: 0.02223803475499153\n",
            "Epoch 139 loss: 0.021971320733428\n",
            "Epoch 140 loss: 0.02170654572546482\n",
            "Epoch 141 loss: 0.02144470438361168\n",
            "Epoch 142 loss: 0.02118699997663498\n",
            "Epoch 143 loss: 0.020933635532855988\n",
            "Epoch 144 loss: 0.020684469491243362\n",
            "Epoch 145 loss: 0.02043992280960083\n",
            "Epoch 146 loss: 0.020200883969664574\n",
            "Epoch 147 loss: 0.019966261461377144\n",
            "Epoch 148 loss: 0.019735507667064667\n",
            "Epoch 149 loss: 0.019508475437760353\n",
            "Epoch 150 loss: 0.01928536780178547\n",
            "Epoch 151 loss: 0.01906617358326912\n",
            "Epoch 152 loss: 0.018850916996598244\n",
            "Epoch 153 loss: 0.01863969676196575\n",
            "Epoch 154 loss: 0.01843213476240635\n",
            "Epoch 155 loss: 0.018228178843855858\n",
            "Epoch 156 loss: 0.01802811771631241\n",
            "Epoch 157 loss: 0.017831698060035706\n",
            "Epoch 158 loss: 0.0176383163779974\n",
            "Epoch 159 loss: 0.01744760200381279\n",
            "Epoch 160 loss: 0.0172592680901289\n",
            "Epoch 161 loss: 0.01707359403371811\n",
            "Epoch 162 loss: 0.016891248524188995\n",
            "Epoch 163 loss: 0.01671217940747738\n",
            "Epoch 164 loss: 0.016536084935069084\n",
            "Epoch 165 loss: 0.016362804919481277\n",
            "Epoch 166 loss: 0.016192352399230003\n",
            "Epoch 167 loss: 0.016024895012378693\n",
            "Epoch 168 loss: 0.015861062332987785\n",
            "Epoch 169 loss: 0.015698334202170372\n",
            "Epoch 170 loss: 0.015537327155470848\n",
            "Epoch 171 loss: 0.015378701500594616\n",
            "Epoch 172 loss: 0.015222660265862942\n",
            "Epoch 173 loss: 0.015069173648953438\n",
            "Epoch 174 loss: 0.014918088912963867\n",
            "Epoch 175 loss: 0.01476945262402296\n",
            "Epoch 176 loss: 0.014623412862420082\n",
            "Epoch 177 loss: 0.014479621313512325\n",
            "Epoch 178 loss: 0.014338100329041481\n",
            "Epoch 179 loss: 0.014198734425008297\n",
            "Epoch 180 loss: 0.014061503112316132\n",
            "Epoch 181 loss: 0.013926664367318153\n",
            "Epoch 182 loss: 0.013793956488370895\n",
            "Epoch 183 loss: 0.013663332909345627\n",
            "Epoch 184 loss: 0.013534693978726864\n",
            "Epoch 185 loss: 0.013408027589321136\n",
            "Epoch 186 loss: 0.013283337466418743\n",
            "Epoch 187 loss: 0.013160510919988155\n",
            "Epoch 188 loss: 0.013039733283221722\n",
            "Epoch 189 loss: 0.012920696288347244\n",
            "Epoch 190 loss: 0.012803375720977783\n",
            "Epoch 191 loss: 0.012687805108726025\n",
            "Epoch 192 loss: 0.012573923915624619\n",
            "Epoch 193 loss: 0.01246168464422226\n",
            "Epoch 194 loss: 0.012350830249488354\n",
            "Epoch 195 loss: 0.012240422889590263\n",
            "Epoch 196 loss: 0.012132303789258003\n",
            "Epoch 197 loss: 0.012025631964206696\n",
            "Epoch 198 loss: 0.011920477263629436\n",
            "Epoch 199 loss: 0.011816972866654396\n",
            "Epoch 200 loss: 0.01171496044844389\n",
            "Epoch 201 loss: 0.011614393442869186\n",
            "Epoch 202 loss: 0.011514456011354923\n",
            "Epoch 203 loss: 0.01141575537621975\n",
            "Epoch 204 loss: 0.011318388395011425\n",
            "Epoch 205 loss: 0.0112222358584404\n",
            "Epoch 206 loss: 0.011127360165119171\n",
            "Epoch 207 loss: 0.011033701710402966\n",
            "Epoch 208 loss: 0.010941330343484879\n",
            "Epoch 209 loss: 0.0108502097427845\n",
            "Epoch 210 loss: 0.010760359466075897\n",
            "Epoch 211 loss: 0.010671336203813553\n",
            "Epoch 212 loss: 0.01058283168822527\n",
            "Epoch 213 loss: 0.010495465248823166\n",
            "Epoch 214 loss: 0.010409217327833176\n",
            "Epoch 215 loss: 0.01032413449138403\n",
            "Epoch 216 loss: 0.010240178555250168\n",
            "Epoch 217 loss: 0.010157505050301552\n",
            "Epoch 218 loss: 0.01007593609392643\n",
            "Epoch 219 loss: 0.009995630010962486\n",
            "Epoch 220 loss: 0.009916417300701141\n",
            "Epoch 221 loss: 0.009838256053626537\n",
            "Epoch 222 loss: 0.009761352092027664\n",
            "Epoch 223 loss: 0.009685641154646873\n",
            "Epoch 224 loss: 0.009611159563064575\n",
            "Epoch 225 loss: 0.009537754580378532\n",
            "Epoch 226 loss: 0.009465334005653858\n",
            "Epoch 227 loss: 0.009393956512212753\n",
            "Epoch 228 loss: 0.009323513135313988\n",
            "Epoch 229 loss: 0.00925404205918312\n",
            "Epoch 230 loss: 0.009185553528368473\n",
            "Epoch 231 loss: 0.00911903940141201\n",
            "Epoch 232 loss: 0.009053466841578484\n",
            "Epoch 233 loss: 0.008988825604319572\n",
            "Epoch 234 loss: 0.008925068192183971\n",
            "Epoch 235 loss: 0.008862322196364403\n",
            "Epoch 236 loss: 0.008800450712442398\n",
            "Epoch 237 loss: 0.008739439770579338\n",
            "Epoch 238 loss: 0.008679290302097797\n",
            "Epoch 239 loss: 0.008619935251772404\n",
            "Epoch 240 loss: 0.008561388589441776\n",
            "Epoch 241 loss: 0.00850365124642849\n",
            "Epoch 242 loss: 0.008446700870990753\n",
            "Epoch 243 loss: 0.008390494622290134\n",
            "Epoch 244 loss: 0.00833501573652029\n",
            "Epoch 245 loss: 0.008280291222035885\n",
            "Epoch 246 loss: 0.008226267993450165\n",
            "Epoch 247 loss: 0.008172986097633839\n",
            "Epoch 248 loss: 0.008120423182845116\n",
            "Epoch 249 loss: 0.00806823093444109\n",
            "Epoch 250 loss: 0.008016148582100868\n",
            "Epoch 251 loss: 0.007964689284563065\n",
            "Epoch 252 loss: 0.007913769222795963\n",
            "Epoch 253 loss: 0.007863479666411877\n",
            "Epoch 254 loss: 0.007813706994056702\n",
            "Epoch 255 loss: 0.007764516398310661\n",
            "Epoch 256 loss: 0.007715897168964148\n",
            "Epoch 257 loss: 0.007667842321097851\n",
            "Epoch 258 loss: 0.00762021541595459\n",
            "Epoch 259 loss: 0.007573144044727087\n",
            "Epoch 260 loss: 0.007526590023189783\n",
            "Epoch 261 loss: 0.007480562198907137\n",
            "Epoch 262 loss: 0.007435011211782694\n",
            "Epoch 263 loss: 0.007389992941170931\n",
            "Epoch 264 loss: 0.007345470599830151\n",
            "Epoch 265 loss: 0.007301435340195894\n",
            "Epoch 266 loss: 0.007257887627929449\n",
            "Epoch 267 loss: 0.007214823272079229\n",
            "Epoch 268 loss: 0.007172245532274246\n",
            "Epoch 269 loss: 0.00713009899482131\n",
            "Epoch 270 loss: 0.007088437210768461\n",
            "Epoch 271 loss: 0.007047230377793312\n",
            "Epoch 272 loss: 0.007006447296589613\n",
            "Epoch 273 loss: 0.006966174114495516\n",
            "Epoch 274 loss: 0.006926270201802254\n",
            "Epoch 275 loss: 0.006886848248541355\n",
            "Epoch 276 loss: 0.006847839802503586\n",
            "Epoch 277 loss: 0.006809172686189413\n",
            "Epoch 278 loss: 0.006770830601453781\n",
            "Epoch 279 loss: 0.006732895504683256\n",
            "Epoch 280 loss: 0.006695365998893976\n",
            "Epoch 281 loss: 0.006658208556473255\n",
            "Epoch 282 loss: 0.006621465086936951\n",
            "Epoch 283 loss: 0.006585250608623028\n",
            "Epoch 284 loss: 0.006549494806677103\n",
            "Epoch 285 loss: 0.006514105945825577\n",
            "Epoch 286 loss: 0.006479123141616583\n",
            "Epoch 287 loss: 0.006444479804486036\n",
            "Epoch 288 loss: 0.006410213652998209\n",
            "Epoch 289 loss: 0.006376342847943306\n",
            "Epoch 290 loss: 0.006342841312289238\n",
            "Epoch 291 loss: 0.0063097719103097916\n",
            "Epoch 292 loss: 0.006277031730860472\n",
            "Epoch 293 loss: 0.006244632415473461\n",
            "Epoch 294 loss: 0.006212540436536074\n",
            "Epoch 295 loss: 0.006181005388498306\n",
            "Epoch 296 loss: 0.006149909924715757\n",
            "Epoch 297 loss: 0.0061191231943666935\n",
            "Epoch 298 loss: 0.0060886200517416\n",
            "Epoch 299 loss: 0.006058441940695047\n",
            "Epoch 300 loss: 0.006028677802532911\n",
            "Epoch 301 loss: 0.005999238695949316\n",
            "Epoch 302 loss: 0.005970111582428217\n",
            "Epoch 303 loss: 0.005941150244325399\n",
            "Epoch 304 loss: 0.005912438500672579\n",
            "Epoch 305 loss: 0.005883896257728338\n",
            "Epoch 306 loss: 0.005855055525898933\n",
            "Epoch 307 loss: 0.005826456006616354\n",
            "Epoch 308 loss: 0.0057980273850262165\n",
            "Epoch 309 loss: 0.005769840907305479\n",
            "Epoch 310 loss: 0.005741860717535019\n",
            "Epoch 311 loss: 0.005714120343327522\n",
            "Epoch 312 loss: 0.005686638411134481\n",
            "Epoch 313 loss: 0.005659403279423714\n",
            "Epoch 314 loss: 0.005632415879517794\n",
            "Epoch 315 loss: 0.005605682265013456\n",
            "Epoch 316 loss: 0.005579206161201\n",
            "Epoch 317 loss: 0.005552986171096563\n",
            "Epoch 318 loss: 0.005527069792151451\n",
            "Epoch 319 loss: 0.005501396022737026\n",
            "Epoch 320 loss: 0.005475983489304781\n",
            "Epoch 321 loss: 0.005450837779790163\n",
            "Epoch 322 loss: 0.005425929557532072\n",
            "Epoch 323 loss: 0.005401309113949537\n",
            "Epoch 324 loss: 0.0053769429214298725\n",
            "Epoch 325 loss: 0.005352818872779608\n",
            "Epoch 326 loss: 0.00532895140349865\n",
            "Epoch 327 loss: 0.005305349826812744\n",
            "Epoch 328 loss: 0.005281990859657526\n",
            "Epoch 329 loss: 0.005258862394839525\n",
            "Epoch 330 loss: 0.005235993303358555\n",
            "Epoch 331 loss: 0.005213363561779261\n",
            "Epoch 332 loss: 0.005190998315811157\n",
            "Epoch 333 loss: 0.005168915260583162\n",
            "Epoch 334 loss: 0.005147151183336973\n",
            "Epoch 335 loss: 0.0051256506703794\n",
            "Epoch 336 loss: 0.005104368552565575\n",
            "Epoch 337 loss: 0.00508329551666975\n",
            "Epoch 338 loss: 0.005062475334852934\n",
            "Epoch 339 loss: 0.005041844677180052\n",
            "Epoch 340 loss: 0.005021487362682819\n",
            "Epoch 341 loss: 0.0050013381987810135\n",
            "Epoch 342 loss: 0.004981408827006817\n",
            "Epoch 343 loss: 0.004961675498634577\n",
            "Epoch 344 loss: 0.004942193161696196\n",
            "Epoch 345 loss: 0.004922911524772644\n",
            "Epoch 346 loss: 0.004903826396912336\n",
            "Epoch 347 loss: 0.004884929396212101\n",
            "Epoch 348 loss: 0.00486623914912343\n",
            "Epoch 349 loss: 0.004847724922001362\n",
            "Epoch 350 loss: 0.004829398822039366\n",
            "Epoch 351 loss: 0.004811244085431099\n",
            "Epoch 352 loss: 0.004793272819370031\n",
            "Epoch 353 loss: 0.004775471985340118\n",
            "Epoch 354 loss: 0.004757855087518692\n",
            "Epoch 355 loss: 0.004740423988550901\n",
            "Epoch 356 loss: 0.004723127465695143\n",
            "Epoch 357 loss: 0.004706006497144699\n",
            "Epoch 358 loss: 0.004689051769673824\n",
            "Epoch 359 loss: 0.004672232083976269\n",
            "Epoch 360 loss: 0.004655599594116211\n",
            "Epoch 361 loss: 0.004639127757400274\n",
            "Epoch 362 loss: 0.004622771870344877\n",
            "Epoch 363 loss: 0.004606479313224554\n",
            "Epoch 364 loss: 0.004590257536619902\n",
            "Epoch 365 loss: 0.004574143793433905\n",
            "Epoch 366 loss: 0.004558132495731115\n",
            "Epoch 367 loss: 0.0045422520488500595\n",
            "Epoch 368 loss: 0.0045265089720487595\n",
            "Epoch 369 loss: 0.004510852042585611\n",
            "Epoch 370 loss: 0.0044953119941055775\n",
            "Epoch 371 loss: 0.004479875788092613\n",
            "Epoch 372 loss: 0.004464456345885992\n",
            "Epoch 373 loss: 0.004449041560292244\n",
            "Epoch 374 loss: 0.004433711990714073\n",
            "Epoch 375 loss: 0.004418460186570883\n",
            "Epoch 376 loss: 0.004403304774314165\n",
            "Epoch 377 loss: 0.004388242494314909\n",
            "Epoch 378 loss: 0.004373268689960241\n",
            "Epoch 379 loss: 0.004358408506959677\n",
            "Epoch 380 loss: 0.004343581385910511\n",
            "Epoch 381 loss: 0.004328765440732241\n",
            "Epoch 382 loss: 0.004314038436859846\n",
            "Epoch 383 loss: 0.0042993901297450066\n",
            "Epoch 384 loss: 0.0042848302982747555\n",
            "Epoch 385 loss: 0.0042703538201749325\n",
            "Epoch 386 loss: 0.004255942068994045\n",
            "Epoch 387 loss: 0.004241607151925564\n",
            "Epoch 388 loss: 0.00422736955806613\n",
            "Epoch 389 loss: 0.004213214386254549\n",
            "Epoch 390 loss: 0.0041991425678133965\n",
            "Epoch 391 loss: 0.004185128957033157\n",
            "Epoch 392 loss: 0.0041714878752827644\n",
            "Epoch 393 loss: 0.004158135503530502\n",
            "Epoch 394 loss: 0.004144906532019377\n",
            "Epoch 395 loss: 0.004131763707846403\n",
            "Epoch 396 loss: 0.004118753131479025\n",
            "Epoch 397 loss: 0.004105868749320507\n",
            "Epoch 398 loss: 0.004093088675290346\n",
            "Epoch 399 loss: 0.004080394748598337\n",
            "Epoch 400 loss: 0.004067801870405674\n",
            "Epoch 401 loss: 0.004055305849760771\n",
            "Epoch 402 loss: 0.004042893182486296\n",
            "Epoch 403 loss: 0.004030573181807995\n",
            "Epoch 404 loss: 0.004018342588096857\n",
            "Epoch 405 loss: 0.0040061743929982185\n",
            "Epoch 406 loss: 0.003994112368673086\n",
            "Epoch 407 loss: 0.003982119262218475\n",
            "Epoch 408 loss: 0.003970221150666475\n",
            "Epoch 409 loss: 0.003958357032388449\n",
            "Epoch 410 loss: 0.0039465888403356075\n",
            "Epoch 411 loss: 0.003934857901185751\n",
            "Epoch 412 loss: 0.003923190291970968\n",
            "Epoch 413 loss: 0.003911589737981558\n",
            "Epoch 414 loss: 0.0039000525139272213\n",
            "Epoch 415 loss: 0.0038885753601789474\n",
            "Epoch 416 loss: 0.0038771384861320257\n",
            "Epoch 417 loss: 0.0038657623808830976\n",
            "Epoch 418 loss: 0.0038544500712305307\n",
            "Epoch 419 loss: 0.0038432925939559937\n",
            "Epoch 420 loss: 0.0038326869253069162\n",
            "Epoch 421 loss: 0.003822135739028454\n",
            "Epoch 422 loss: 0.0038116169162094593\n",
            "Epoch 423 loss: 0.003801156533882022\n",
            "Epoch 424 loss: 0.0037907566875219345\n",
            "Epoch 425 loss: 0.0037804299499839544\n",
            "Epoch 426 loss: 0.003770139766857028\n",
            "Epoch 427 loss: 0.003759916638955474\n",
            "Epoch 428 loss: 0.003749765455722809\n",
            "Epoch 429 loss: 0.003739677369594574\n",
            "Epoch 430 loss: 0.0037296563386917114\n",
            "Epoch 431 loss: 0.003719705855473876\n",
            "Epoch 432 loss: 0.0037098100874572992\n",
            "Epoch 433 loss: 0.00369995622895658\n",
            "Epoch 434 loss: 0.0036901908461004496\n",
            "Epoch 435 loss: 0.0036804890260100365\n",
            "Epoch 436 loss: 0.0036708442494273186\n",
            "Epoch 437 loss: 0.0036612588446587324\n",
            "Epoch 438 loss: 0.0036517197731882334\n",
            "Epoch 439 loss: 0.0036422633565962315\n",
            "Epoch 440 loss: 0.0036328511778265238\n",
            "Epoch 441 loss: 0.003623501630499959\n",
            "Epoch 442 loss: 0.00361419003456831\n",
            "Epoch 443 loss: 0.0036049389746040106\n",
            "Epoch 444 loss: 0.0035957531072199345\n",
            "Epoch 445 loss: 0.003586612641811371\n",
            "Epoch 446 loss: 0.0035775185097008944\n",
            "Epoch 447 loss: 0.0035684676840901375\n",
            "Epoch 448 loss: 0.003559474367648363\n",
            "Epoch 449 loss: 0.0035505422856658697\n",
            "Epoch 450 loss: 0.003541636746376753\n",
            "Epoch 451 loss: 0.003532798495143652\n",
            "Epoch 452 loss: 0.003524195635691285\n",
            "Epoch 453 loss: 0.003515717340633273\n",
            "Epoch 454 loss: 0.0035072248429059982\n",
            "Epoch 455 loss: 0.003498752135783434\n",
            "Epoch 456 loss: 0.0034903213381767273\n",
            "Epoch 457 loss: 0.003481911960989237\n",
            "Epoch 458 loss: 0.0034735354129225016\n",
            "Epoch 459 loss: 0.003465218935161829\n",
            "Epoch 460 loss: 0.003456961130723357\n",
            "Epoch 461 loss: 0.003448782954365015\n",
            "Epoch 462 loss: 0.0034407740458846092\n",
            "Epoch 463 loss: 0.0034327423200011253\n",
            "Epoch 464 loss: 0.003424748545512557\n",
            "Epoch 465 loss: 0.003416852094233036\n",
            "Epoch 466 loss: 0.003409041091799736\n",
            "Epoch 467 loss: 0.003401255002245307\n",
            "Epoch 468 loss: 0.003393505234271288\n",
            "Epoch 469 loss: 0.0033857999369502068\n",
            "Epoch 470 loss: 0.0033781591337174177\n",
            "Epoch 471 loss: 0.0033705735113471746\n",
            "Epoch 472 loss: 0.0033630544785410166\n",
            "Epoch 473 loss: 0.003355596913024783\n",
            "Epoch 474 loss: 0.003348200349137187\n",
            "Epoch 475 loss: 0.003340825205668807\n",
            "Epoch 476 loss: 0.003333519911393523\n",
            "Epoch 477 loss: 0.003326270030811429\n",
            "Epoch 478 loss: 0.003319079289212823\n",
            "Epoch 479 loss: 0.0033119404688477516\n",
            "Epoch 480 loss: 0.003304853802546859\n",
            "Epoch 481 loss: 0.003297803457826376\n",
            "Epoch 482 loss: 0.003290815744549036\n",
            "Epoch 483 loss: 0.0032838834449648857\n",
            "Epoch 484 loss: 0.0032768838573247194\n",
            "Epoch 485 loss: 0.003269552020356059\n",
            "Epoch 486 loss: 0.0032621899154037237\n",
            "Epoch 487 loss: 0.0032547765877097845\n",
            "Epoch 488 loss: 0.003247320419177413\n",
            "Epoch 489 loss: 0.003239850513637066\n",
            "Epoch 490 loss: 0.0032323456835001707\n",
            "Epoch 491 loss: 0.0032248434145003557\n",
            "Epoch 492 loss: 0.0032173306681215763\n",
            "Epoch 493 loss: 0.003209813265129924\n",
            "Epoch 494 loss: 0.0032023009844124317\n",
            "Epoch 495 loss: 0.0031947921961545944\n",
            "Epoch 496 loss: 0.0031872978433966637\n",
            "Epoch 497 loss: 0.00317978672683239\n",
            "Epoch 498 loss: 0.003172303084284067\n",
            "Epoch 499 loss: 0.0031648355070501566\n"
          ]
        }
      ],
      "source": [
        "neuron_1 = Linear(1, 100)\n",
        "neuron_2 = Linear(100, 1)\n",
        "loss = MSELoss()\n",
        "activation = ReLU()\n",
        "optimizer = optim.Adam([{'params': neuron_1.parameters()}, {'params': neuron_2.parameters()}], lr=0.01)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(500):\n",
        "    # forward pass\n",
        "    y_pred = neuron_2.forward(activation.forward(neuron_1.forward(X)))\n",
        "    # y_pred = neuron_2.forward(neuron_1.forward(X))\n",
        "    curr_loss = loss.forward(y_pred, y)\n",
        "    losses.append(curr_loss)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.forward(y_pred, y).backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch} loss: {curr_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "FgDSoX7WkHZe",
        "outputId": "4c49a35f-22c2-4d8c-bc51-c1f2496ee5f6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.no_grad():\n",
        "  plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "fPsUewwlgHsZ",
        "outputId": "a32f1754-3c0a-49bb-9113-24505d87b229"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.no_grad():\n",
        "  plt.plot(X, y)\n",
        "  plt.plot(X, neuron_2.forward(activation.forward(neuron_1.forward(X))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-qUqdALiN-G"
      },
      "source": [
        "## 3.3 Построение сетей при помощи `torch.nn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vxsck-1M6TAV"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0ICJtarif3_"
      },
      "source": [
        "3.3.1 Решить задачу регрессии, соблюдая следующие условия:\n",
        "\n",
        "1. Оформить нейронную сеть в виде класса - наследника `nn.Module`\n",
        "2. При создании сети использовать готовые блоки из `torch.nn`: слои, функции активации, функции потерь и т.д.\n",
        "3. Для оптимизации использовать любой алгоритм оптимизации из `torch.optim` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1bvXHhO7aWs"
      },
      "outputs": [],
      "source": [
        "X = torch.linspace(0, 1, 100).view(-1, 1)\n",
        "y = torch.sin(2 * np.pi * X) + 0.1 * torch.rand(X.size()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEByJj2TOkfv",
        "outputId": "30070bfd-d324-4315-cfce-8c53f7e448ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: 0.5386536121368408\n",
            "Epoch 100 loss: 0.31417039036750793\n",
            "Epoch 200 loss: 0.18773768842220306\n",
            "Epoch 300 loss: 0.1847917139530182\n",
            "Epoch 400 loss: 0.18054021894931793\n",
            "Epoch 500 loss: 0.17463484406471252\n",
            "Epoch 600 loss: 0.166963592171669\n",
            "Epoch 700 loss: 0.15761804580688477\n",
            "Epoch 800 loss: 0.1465131938457489\n",
            "Epoch 900 loss: 0.13235145807266235\n",
            "Epoch 1000 loss: 0.11186767369508743\n",
            "Epoch 1100 loss: 0.08399713784456253\n",
            "Epoch 1200 loss: 0.055266790091991425\n",
            "Epoch 1300 loss: 0.033549126237630844\n",
            "Epoch 1400 loss: 0.02091931365430355\n",
            "Epoch 1500 loss: 0.014945938251912594\n",
            "Epoch 1600 loss: 0.01244619581848383\n",
            "Epoch 1700 loss: 0.01135332603007555\n",
            "Epoch 1800 loss: 0.010719925165176392\n",
            "Epoch 1900 loss: 0.010149325244128704\n"
          ]
        }
      ],
      "source": [
        "class SineNet(torch.nn.Module):\n",
        "    def __init__(self, n_hidden_neurons):\n",
        "        super(SineNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(1, n_hidden_neurons)\n",
        "        self.act1 = torch.nn.Sigmoid()\n",
        "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "neuron = SineNet(3)\n",
        "optimizer = optim.Adam(neuron.parameters(), lr=0.01)\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(2000):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = neuron.forward(X)\n",
        "    loss_val = loss(y_pred, y)\n",
        "\n",
        "    loss_val.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 100 == 0: print(f\"Epoch {epoch} loss: {loss_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "juoPyUI8hG_v",
        "outputId": "5ed0b4b0-440c-45f3-a5aa-7be34fa33fc7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  plt.plot(X, y)\n",
        "  plt.plot(X, neuron(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPUW6fm5jbQd"
      },
      "source": [
        "3.3.2 Решить задачу регрессии, соблюдая следующие условия:\n",
        "\n",
        "1. Оформить нейронную сеть в виде объекта `nn.Sequential`\n",
        "2. При создании сети использовать готовые блоки из `torch.nn`: слои, функции активации, функции потерь и т.д.\n",
        "3. Для оптимизации использовать любой алгоритм оптимизации из `torch.optim` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBwbAEd57a2r",
        "outputId": "4c822056-6aa5-4307-ae01-65d98e2d5683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: 0.4876212775707245\n",
            "Epoch 100 loss: 0.19528909027576447\n",
            "Epoch 200 loss: 0.18962225317955017\n",
            "Epoch 300 loss: 0.1878425031900406\n",
            "Epoch 400 loss: 0.18477432429790497\n",
            "Epoch 500 loss: 0.17927859723567963\n",
            "Epoch 600 loss: 0.16958017647266388\n",
            "Epoch 700 loss: 0.1550215631723404\n",
            "Epoch 800 loss: 0.12056023627519608\n",
            "Epoch 900 loss: 0.06769632548093796\n",
            "Epoch 1000 loss: 0.028309235349297523\n",
            "Epoch 1100 loss: 0.01058168150484562\n",
            "Epoch 1200 loss: 0.005030478350818157\n",
            "Epoch 1300 loss: 0.0035396453458815813\n",
            "Epoch 1400 loss: 0.0028025314677506685\n",
            "Epoch 1500 loss: 0.002277930034324527\n",
            "Epoch 1600 loss: 0.0018953063990920782\n",
            "Epoch 1700 loss: 0.0016175475902855396\n",
            "Epoch 1800 loss: 0.0014145689783617854\n",
            "Epoch 1900 loss: 0.0012705614790320396\n"
          ]
        }
      ],
      "source": [
        "X = torch.linspace(0, 1, 100).view(-1, 1)\n",
        "y = torch.sin(2 * np.pi * X) + 0.1 * torch.rand(X.size()) \n",
        "\n",
        "layers = [\n",
        "    torch.nn.Linear(1, 5),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Linear(5, 1)\n",
        "]\n",
        "model = torch.nn.Sequential(*layers)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(2000):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model.forward(X)\n",
        "    loss_val = loss(y_pred, y)\n",
        "\n",
        "    loss_val.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 100 == 0: print(f\"Epoch {epoch} loss: {loss_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9D4LRdHjhdiF",
        "outputId": "c0c96802-80d0-4838-c2ba-b49e3c66fa54"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  plt.plot(X, y)\n",
        "  plt.plot(X, model(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQj0oVeLj2A1"
      },
      "source": [
        "## 3.4. Datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c82tAkXMjajm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoFPckkp8yhz"
      },
      "source": [
        "3.4.1 Создать датасет, поставляющий данные из задачи 3.1.2. \n",
        "\n",
        "Создать `DataLoader` на основе этого датасета и проверить работоспособность.\n",
        "\n",
        "Воспользовавшись результатами 3.3.1 (или 3.3.2) обучите модель, пользуясь мини-пакетным градиентным спуском с размером пакета (`batch_size`) = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlcwQzCFRvFc"
      },
      "outputs": [],
      "source": [
        "class SinDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.X = torch.linspace(0, 1, 100).view(-1, 1)\n",
        "    self.y = torch.sin(2 * np.pi * self.X) + 0.1 * torch.rand(self.X.size()) \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrwwWTsSjK6b",
        "outputId": "77b4ad82-7c92-41d2-cb0d-92236147c44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: 0.1360023468732834\n",
            "Epoch 100 loss: 0.023825522512197495\n",
            "Epoch 200 loss: 0.021264640614390373\n",
            "Epoch 300 loss: 0.01690227910876274\n",
            "Epoch 400 loss: 0.01045158039778471\n",
            "Epoch 500 loss: 0.004398830235004425\n",
            "Epoch 600 loss: 0.001501718652434647\n",
            "Epoch 700 loss: 0.000864460482262075\n",
            "Epoch 800 loss: 0.000791870232205838\n",
            "Epoch 900 loss: 0.0007812554249539971\n",
            "Epoch 1000 loss: 0.000773935578763485\n",
            "Epoch 1100 loss: 0.0007664604345336556\n",
            "Epoch 1200 loss: 0.0007588525186292827\n",
            "Epoch 1300 loss: 0.000751226325519383\n",
            "Epoch 1400 loss: 0.0007436712039634585\n",
            "Epoch 1500 loss: 0.0007362522301264107\n",
            "Epoch 1600 loss: 0.0007290017092600465\n",
            "Epoch 1700 loss: 0.0007219315739348531\n",
            "Epoch 1800 loss: 0.0007150302990339696\n",
            "Epoch 1900 loss: 0.0007082775118760765\n"
          ]
        }
      ],
      "source": [
        "class SineNet(torch.nn.Module):\n",
        "    def __init__(self, n_hidden_neurons):\n",
        "        super(SineNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(1, n_hidden_neurons)\n",
        "        self.act1 = torch.nn.Sigmoid()\n",
        "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "neuron = SineNet(3)\n",
        "optimizer = optim.Adam(neuron.parameters(), lr=0.01)\n",
        "loss = torch.nn.MSELoss()\n",
        "dataloader = DataLoader(SinDataset(), batch_size=10)\n",
        "\n",
        "for epoch in range(2000):\n",
        "    X_new, y_new = next(iter(dataloader))\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = neuron.forward(X_new)\n",
        "    loss_val = loss(y_pred, y_new)\n",
        "\n",
        "    loss_val.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 100 == 0: print(f\"Epoch {epoch} loss: {loss_val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxz02a3k_VQL"
      },
      "source": [
        "3.4.2 Предсказание цен алмазов\n",
        "\n",
        "3.4.2.1 Создайте датасет на основе файла diamonds.csv. \n",
        "\n",
        "1. Удалите все нечисловые столбцы\n",
        "2. Целевой столбец (`y`) - `price`\n",
        "3. Преобразуйте данные в тензоры корректных размеров\n",
        "\n",
        "3.4.2.2 Разбейте датасет на обучающий и тестовый датасет при помощи `torch.utils.data.random_split`.\n",
        "\n",
        "3.4.2.3 Обучите модель для предсказания цен при помощи мини-пакетного градиентного спуска (`batch_size = 256`). \n",
        "\n",
        "3.4.2.4 Выведите график функции потерь в зависимости от номера эпохи (значение потерь для эпохи рассчитывайте как среднее значение ошибок на каждом батче). Проверьте качество модели на тестовой выборке. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fEfTNJQI8emD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class DiamondsDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    super().__init__()\n",
        "    self.data = pd.read_csv(data, index_col = [0])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    self.X = torch.FloatTensor(self.data.select_dtypes(['number']).values)\n",
        "    self.y = torch.FloatTensor(self.data['price'].values)\n",
        "    return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "al0bfhffl2j8"
      },
      "outputs": [],
      "source": [
        "dataset = DiamondsDataset('diamonds.csv')\n",
        "\n",
        "train, test = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), int(len(dataset)*0.2)])\n",
        "\n",
        "diamonds_dataloader_train = DataLoader(train, batch_size=256)\n",
        "diamonds_dataloader_test = DataLoader(test, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDq4c2ApnClp",
        "outputId": "76fc0032-a9f9-454e-c2e7-3d99ddf330bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 24152918.0\n",
            "Epoch 1 loss: 13928083.0\n",
            "Epoch 2 loss: 12949975.0\n",
            "Epoch 3 loss: 12751903.0\n",
            "Epoch 4 loss: 12711796.0\n",
            "Epoch 5 loss: 12703672.0\n",
            "Epoch 6 loss: 12702028.0\n",
            "Epoch 7 loss: 12701696.0\n",
            "Epoch 8 loss: 12701627.0\n",
            "Epoch 9 loss: 12701614.0\n",
            "Epoch 10 loss: 12701611.0\n",
            "Epoch 11 loss: 12701612.0\n",
            "Epoch 12 loss: 12701611.0\n",
            "Epoch 13 loss: 12701610.0\n",
            "Epoch 14 loss: 12701610.0\n",
            "Epoch 15 loss: 12701611.0\n",
            "Epoch 16 loss: 12701611.0\n",
            "Epoch 17 loss: 12701610.0\n",
            "Epoch 18 loss: 12701611.0\n",
            "Epoch 19 loss: 12701611.0\n"
          ]
        }
      ],
      "source": [
        "class DiamondsNet(torch.nn.Module):\n",
        "    def __init__(self, n_hidden_neurons, n_features):\n",
        "        super(DiamondsNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(n_hidden_neurons, n_features)\n",
        "        self.act1 = torch.nn.Sigmoid()\n",
        "        self.fc2 = torch.nn.Linear(n_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "neuron = DiamondsNet(7, 49)\n",
        "optimizer = torch.optim.SGD(neuron.parameters(), lr=0.025)\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "loss_vals = []\n",
        "for epoch in range(20):\n",
        "    X_new, y_new = next(iter(diamonds_dataloader_train))\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = neuron.forward(X_new)\n",
        "    loss_val = loss(y_pred, y_new)\n",
        "    loss_vals.append(loss_val)\n",
        "\n",
        "    loss_val.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    print(f\"Epoch {epoch} loss: {loss_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "rKgh0WHOu437",
        "outputId": "b74b4eaf-87c4-4ddb-c287-26a13c7d5522"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.no_grad():\n",
        "  plt.plot(loss_vals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE81cgQdGM7I"
      },
      "source": [
        "3.4.3 Модифицируйте метод `__init__` датасета из 3.4.2 таким образом, чтобы он мог принимать параметр `transform: callable`. Реализуйте класс `DropColsTransform` для удаления нечисловых данных из массива. Реализуйте класс `ToTensorTransorm` для трансформации массива в тензор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "J02LNj_F8qxK"
      },
      "outputs": [],
      "source": [
        "class DiamondsDataset(Dataset):\n",
        "  def __init__(self, data, transform=None):\n",
        "    self.data = pd.read_csv(data, index_col = [0])\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    X = self.data.drop('price', axis=1)\n",
        "    y = self.data['price']\n",
        "    sample = X.iloc[idx], y.iloc[idx]\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "tJii-22pHIlU"
      },
      "outputs": [],
      "source": [
        "class DropColsTransform:\n",
        "  def __init__(self, drop):\n",
        "    self.drop = drop\n",
        "  \n",
        "  def __call__(self, sample):\n",
        "    X, y = sample\n",
        "    X = X.drop(X.index[self.drop], axis=0)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "dZZ-OKrVHnY5"
      },
      "outputs": [],
      "source": [
        "class ToTensorTransform:\n",
        "  def __call__(self, sample):\n",
        "    X, y = sample\n",
        "    X = torch.FloatTensor(X.astype('float64').values)\n",
        "    y = torch.FloatTensor([y])\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "GssBjT9JHt5g"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "drop = DropColsTransform(drop=[1, 2, 3])\n",
        "to_tensor = ToTensorTransform()\n",
        "dataset = DiamondsDataset('diamonds.csv', transform=transforms.Compose([drop, to_tensor]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), int(len(dataset)*0.2)])\n",
        "\n",
        "diamonds_dataloader_train = DataLoader(train, batch_size=256)\n",
        "diamonds_dataloader_test = DataLoader(test, batch_size=256)"
      ],
      "metadata": {
        "id": "qCcwrng5ogB0"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiamondsNet(torch.nn.Module):\n",
        "    def __init__(self, n_hidden_neurons, n_features):\n",
        "        super(DiamondsNet, self).__init__()\n",
        "        self.net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(n_features, n_hidden_neurons), \n",
        "            torch.nn.Sigmoid(), \n",
        "            torch.nn.Linear(n_hidden_neurons,n_hidden_neurons),\n",
        "            torch.nn.Sigmoid(),\n",
        "            torch.nn.Linear(n_hidden_neurons,n_hidden_neurons*2),\n",
        "            torch.nn.Sigmoid(),\n",
        "            torch.nn.Linear(n_hidden_neurons*2,1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x\n",
        "\n",
        "neuron = DiamondsNet(16, 6)\n",
        "optimizer = torch.optim.SGD(neuron.parameters(), lr=0.01)\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "loss_vals = []\n",
        "for epoch in range(20):\n",
        "    X_new, y_new = next(iter(diamonds_dataloader_train))\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = neuron.forward(X_new)\n",
        "    loss_val = loss(y_pred, y_new)\n",
        "    loss_vals.append(loss_val)\n",
        "\n",
        "    loss_val.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    print(f\"Epoch {epoch} loss: {loss_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG30lIUcrHTU",
        "outputId": "ae1f39f2-9ea4-4cb5-d845-cedf183815c6"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 31515842.0\n",
            "Epoch 1 loss: 27090798.0\n",
            "Epoch 2 loss: 19535812.0\n",
            "Epoch 3 loss: 16133378.0\n",
            "Epoch 4 loss: 15017710.0\n",
            "Epoch 5 loss: 14800786.0\n",
            "Epoch 6 loss: 14750708.0\n",
            "Epoch 7 loss: 14736909.0\n",
            "Epoch 8 loss: 14736092.0\n",
            "Epoch 9 loss: 14735919.0\n",
            "Epoch 10 loss: 14735880.0\n",
            "Epoch 11 loss: 14735872.0\n",
            "Epoch 12 loss: 14735872.0\n",
            "Epoch 13 loss: 14735872.0\n",
            "Epoch 14 loss: 14735872.0\n",
            "Epoch 15 loss: 14735870.0\n",
            "Epoch 16 loss: 14735872.0\n",
            "Epoch 17 loss: 14735870.0\n",
            "Epoch 18 loss: 14735872.0\n",
            "Epoch 19 loss: 14735871.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  plt.plot(loss_vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "842E2m3MtdpF",
        "outputId": "4de78a70-8197-4286-83e0-b85e65962ac0"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}