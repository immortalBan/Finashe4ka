{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"ПИ19-2\"\n",
    "s2 = \"ПИ19-1\"\n",
    "edit_distance(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['высокопревосходительства',\n",
       " 'попреблагорассмотрительст',\n",
       " 'попреблагорассмотрительствующемуся',\n",
       " 'убегающих',\n",
       " 'уменьшившейся']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''\n",
    "with open (\"./litw-win.txt\", \"r\", encoding='windows-1251') as fp:\n",
    "    words = [line.strip().split()[-1] for line in fp]\n",
    "words[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'с величайшим усилием выбравшись из потока убегающих людей кутузов со свитой уменьшившейся вдвое поехал на звуки выстрелов русских орудий'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([min(words, key=lambda w: edit_distance(w, t)) for t in text.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "с\n",
      "велечайш\n",
      "усил\n",
      "выбра\n",
      "из\n",
      "поток\n",
      "убега\n",
      "люд\n",
      "кутуз\n",
      "со\n",
      "свит\n",
      "уменьшевш\n",
      "вдво\n",
      "поеха\n",
      "на\n",
      "звук\n",
      "выстрел\n",
      "русск\n",
      "оруд\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('russian')\n",
    "\n",
    "for word in word_tokenize(text):\n",
    "    result = stemmer.stem(word)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "с\n",
      "велечайший\n",
      "усилие\n",
      "выбраться\n",
      "из\n",
      "поток\n",
      "убегать\n",
      "человек\n",
      "кутузов\n",
      "с\n",
      "свита\n",
      "уменьшевшийся\n",
      "вдвое\n",
      "поехать\n",
      "на\n",
      "звук\n",
      "выстрел\n",
      "русский\n",
      "орудие\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "for word in word_tokenize(text):\n",
    "    result = morph.parse(word)[0].normalized.word\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Считайте слова из файла `litw-win.txt` и запишите их в список `words`.',\n",
       " 'В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`.',\n",
       " 'Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. '''\n",
    "sents = sent_tokenize(text)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(sents)\n",
    "sents_cv = cv.transform(sents).toarray()\n",
    "sents_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'считайте': 32,\n",
       " 'слова': 24,\n",
       " 'из': 12,\n",
       " 'файла': 33,\n",
       " 'litw': 0,\n",
       " 'win': 2,\n",
       " 'txt': 1,\n",
       " 'запишите': 11,\n",
       " 'их': 14,\n",
       " 'список': 31,\n",
       " 'words': 3,\n",
       " 'заданном': 9,\n",
       " 'предложении': 22,\n",
       " 'исправьте': 13,\n",
       " 'все': 5,\n",
       " 'опечатки': 21,\n",
       " 'заменив': 10,\n",
       " 'опечатками': 20,\n",
       " 'на': 16,\n",
       " 'ближайшие': 4,\n",
       " 'смысле': 27,\n",
       " 'расстояния': 23,\n",
       " 'левенштейна': 15,\n",
       " 'ним': 18,\n",
       " 'списка': 29,\n",
       " 'что': 34,\n",
       " 'слове': 25,\n",
       " 'есть': 8,\n",
       " 'опечатка': 19,\n",
       " 'если': 7,\n",
       " 'данное': 6,\n",
       " 'слово': 26,\n",
       " 'не': 17,\n",
       " 'содержится': 28,\n",
       " 'списке': 30}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>these were so go it surprised even me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>my sisterinlaw made these for us at a family g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      name  \\\n",
       "0   0     george s at the cove  black bean soup   \n",
       "1   1        healthy for them  yogurt popsicles   \n",
       "2   2              i can t believe it s spinach   \n",
       "3   3                      italian  gut busters   \n",
       "4   4  love is in the air  beef fondue   sauces   \n",
       "\n",
       "                           preprocessed_descriptions  \n",
       "0  an original recipe created by chef scott meska...  \n",
       "1  my children and their friends ask for my homem...  \n",
       "2              these were so go it surprised even me  \n",
       "3  my sisterinlaw made these for us at a family g...  \n",
       "4  i think a fondue is a very romantic casual din...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preprocessed_descriptions = pd.read_csv(\"./preprocessed_descriptions.csv\")\n",
    "preprocessed_descriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'original',\n",
       " 'recipe',\n",
       " 'created',\n",
       " 'by',\n",
       " 'chef',\n",
       " 'scott',\n",
       " 'meskan',\n",
       " 'georges',\n",
       " 'at',\n",
       " 'the',\n",
       " 'cove',\n",
       " 'we',\n",
       " 'enjoyed',\n",
       " 'this',\n",
       " 'when',\n",
       " 'we',\n",
       " 'visited',\n",
       " 'this',\n",
       " 'restaurant']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "words = reduce(lambda x,y: x + y, [word_tokenize(item) for item in preprocessed_descriptions[\"preprocessed_descriptions\"].to_list() if isinstance(item, str)])\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bueno',\n",
       " 'recipesliced',\n",
       " 'exhausting',\n",
       " 'cookedmashed',\n",
       " 'differenttry',\n",
       " 'homemaker',\n",
       " 'smokies',\n",
       " 'doodlefathr',\n",
       " 'cored',\n",
       " 'lesssweet',\n",
       " 'gutsy',\n",
       " 'cous',\n",
       " 'splash',\n",
       " 'spezie',\n",
       " 'fruits',\n",
       " 'force',\n",
       " 'beacha',\n",
       " 'encore',\n",
       " 'mangoflavored',\n",
       " 'recfoodbaking']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(words))\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sid', 'et'],\n",
       " ['term', 'spanakopita'],\n",
       " ['sackthis', 'thornberryit'],\n",
       " ['saladises', 'bloody'],\n",
       " ['wintertime', 'burritostyle']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "pairs = [rd.choices(words, k=2) for _ in range(5)]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 11, 11, 8, 9]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_s = [edit_distance(*pair) for pair in pairs]\n",
    "h_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term', 'teri', 'team']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k_nearest(word, k=1):\n",
    "    w_new = sorted(words, key=lambda w: edit_distance(w, word))\n",
    "    return w_new[:k]\n",
    "\n",
    "k_nearest('term', k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ivanb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stemmed_word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gutsy</th>\n",
       "      <td>gutsy</td>\n",
       "      <td>gutsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cous</th>\n",
       "      <td>cous</td>\n",
       "      <td>cous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splash</th>\n",
       "      <td>splash</td>\n",
       "      <td>splash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spezie</th>\n",
       "      <td>spezie</td>\n",
       "      <td>spezie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruits</th>\n",
       "      <td>fruits</td>\n",
       "      <td>fruit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word normalized_word\n",
       "stemmed_word                        \n",
       "gutsy          gutsy           gutsy\n",
       "cous            cous            cous\n",
       "splash        splash          splash\n",
       "spezie        spezie          spezie\n",
       "fruits        fruits           fruit"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "normalized_word = [lemmatizer.lemmatize(word) for word in words]\n",
    "df = pd.DataFrame(list(zip(words, stemmed_words, normalized_word))[10:20], columns=['word', 'stemmed_word', 'normalized_word'])\n",
    "df = df.set_index('stemmed_word')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ivanb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "st_w = stopwords.words()\n",
    "texts = reduce(lambda x, y: x + ' ' + y, [item for item in preprocessed_descriptions[\"preprocessed_descriptions\"].to_list() if isinstance(item, str)])\n",
    "tokens = word_tokenize(texts)\n",
    "l = len(tokens)\n",
    "l_new = 0\n",
    "words_dict = {}\n",
    "words_dict_stop = {}\n",
    "for w in tokens:\n",
    "    if w not in st_w:\n",
    "        words_dict_stop[w] = words_dict_stop.get(w, 0) + 1\n",
    "        l_new += 1\n",
    "    words_dict[w] = words_dict.get(w, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля стоп слов - 0.47034287456488355\n",
      "Топ 10 слов со стоп словами: the a and this i to is it of for\n",
      "Топ 10 слов без стоп слов: recipe make time use great like easy made good dish\n"
     ]
    }
   ],
   "source": [
    "print(f'Доля стоп слов - {(l - l_new) / l}')\n",
    "print(f'Топ 10 слов со стоп словами: {\" \".join(sorted(words_dict.keys(), key=lambda x: words_dict[x], reverse=True)[:10])}')\n",
    "print(f'Топ 10 слов без стоп слов: {\" \".join(sorted(words_dict_stop.keys(), key=lambda x: words_dict_stop[x], reverse=True)[:10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this recipe originally came from the usa weekend paper i changed a few things around to suit us and this is the end result',\n",
       " 'a well known and delicious arabic sweet commonly eaten in countries like palestine and jordan this is a variation that my family does that does not contain sweet cheese unlike other kenafe recipes this one taste delicious reheated',\n",
       " 'these are delicious cornish game hens they take awhile to prepare but are worth it i have tripled the recipe these are a family favorite i found the recipe some time ago on the web',\n",
       " 'this is a fun recipe  kids will love it  i serve with a jarred marinara sauce that i jazz up a little  i have also tried this recipe using pork chops cut into thin strips  both ways are excellent  enjoy',\n",
       " 'the pizza stone we bought came with recipes  this is one of them  i havent tried it yet but it looks really really good']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "rd_recepies = rd.choices(preprocessed_descriptions[\"preprocessed_descriptions\"], k=5)\n",
    "rd_recepies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(rd_recepies)\n",
    "sent_vec = vectorizer.transform(rd_recepies)\n",
    "sent_vec = sent_vec.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('this recipe originally came from the usa weekend paper i changed a few things around to suit us and this is the end result', 'a well known and delicious arabic sweet commonly eaten in countries like palestine and jordan this is a variation that my family does that does not contain sweet cheese unlike other kenafe recipes this one taste delicious reheated'): 0.8937396582041199, ('this recipe originally came from the usa weekend paper i changed a few things around to suit us and this is the end result', 'these are delicious cornish game hens they take awhile to prepare but are worth it i have tripled the recipe these are a family favorite i found the recipe some time ago on the web'): 0.8355859919279524, ('this recipe originally came from the usa weekend paper i changed a few things around to suit us and this is the end result', 'this is a fun recipe  kids will love it  i serve with a jarred marinara sauce that i jazz up a little  i have also tried this recipe using pork chops cut into thin strips  both ways are excellent  enjoy'): 0.8955008246343484, ('this recipe originally came from the usa weekend paper i changed a few things around to suit us and this is the end result', 'the pizza stone we bought came with recipes  this is one of them  i havent tried it yet but it looks really really good'): 0.8734571524539027, ('a well known and delicious arabic sweet commonly eaten in countries like palestine and jordan this is a variation that my family does that does not contain sweet cheese unlike other kenafe recipes this one taste delicious reheated', 'these are delicious cornish game hens they take awhile to prepare but are worth it i have tripled the recipe these are a family favorite i found the recipe some time ago on the web'): 0.9476740474958096, ('a well known and delicious arabic sweet commonly eaten in countries like palestine and jordan this is a variation that my family does that does not contain sweet cheese unlike other kenafe recipes this one taste delicious reheated', 'this is a fun recipe  kids will love it  i serve with a jarred marinara sauce that i jazz up a little  i have also tried this recipe using pork chops cut into thin strips  both ways are excellent  enjoy'): 0.9160391316094251, ('a well known and delicious arabic sweet commonly eaten in countries like palestine and jordan this is a variation that my family does that does not contain sweet cheese unlike other kenafe recipes this one taste delicious reheated', 'the pizza stone we bought came with recipes  this is one of them  i havent tried it yet but it looks really really good'): 0.9211810052911804, ('these are delicious cornish game hens they take awhile to prepare but are worth it i have tripled the recipe these are a family favorite i found the recipe some time ago on the web', 'this is a fun recipe  kids will love it  i serve with a jarred marinara sauce that i jazz up a little  i have also tried this recipe using pork chops cut into thin strips  both ways are excellent  enjoy'): 0.8514807468292198, ('these are delicious cornish game hens they take awhile to prepare but are worth it i have tripled the recipe these are a family favorite i found the recipe some time ago on the web', 'the pizza stone we bought came with recipes  this is one of them  i havent tried it yet but it looks really really good'): 0.8933119420127926, ('this is a fun recipe  kids will love it  i serve with a jarred marinara sauce that i jazz up a little  i have also tried this recipe using pork chops cut into thin strips  both ways are excellent  enjoy', 'the pizza stone we bought came with recipes  this is one of them  i havent tried it yet but it looks really really good'): 0.8739812969883332}\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "d_dist = {}\n",
    "for i in range(sent_vec.shape[0] - 1):\n",
    "    for j in range(i + 1, sent_vec.shape[0]):\n",
    "        d_dist[(rd_recepies[i], rd_recepies[j])] = distance.cosine(sent_vec[i], sent_vec[j])\n",
    "print(d_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a well known and delicious arabic sweet commonly eaten in countries like palestine and jordan this is a variation that my family does that does not contain sweet cheese unlike other kenafe recipes this one taste delicious reheated', 'these are delicious cornish game hens they take awhile to prepare but are worth it i have tripled the recipe these are a family favorite i found the recipe some time ago on the web')\n",
      "0.9476740474958096\n"
     ]
    }
   ],
   "source": [
    "m = max(d_dist.keys(), key=lambda x: d_dist[x])\n",
    "print(m)\n",
    "print(d_dist[m])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
